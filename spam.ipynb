{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 1601\n",
      "Legit messages: 1119\n",
      "Spam messages: 161\n",
      "Smishing messages: 321\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "\n",
    "# specify location your dataset here\n",
    "DATA_PATH = r\"C:\\Users\\User\\Documents\\Git\\yaroslav tomek\\data\\dataset.txt\"\n",
    "\n",
    "# give name to label-column and text-column\n",
    "COLUMN_LABEL = \"label\"\n",
    "COLUMN_TEXT = \"text\"\n",
    "\n",
    "# these are labels that indicate the type of message.\n",
    "LABEL_LEGIT = 'LEGI'\n",
    "LABEL_SPAM = 'SPAM'\n",
    "LABEL_SMISHING = 'SMIS'\n",
    "\n",
    "dataset = pd.read_csv(DATA_PATH, sep='\\t', names=[COLUMN_LABEL, COLUMN_TEXT], header=None)\n",
    "print('Total size:', dataset.shape[0])\n",
    "print('Legit messages:', dataset[dataset[COLUMN_LABEL] == LABEL_LEGIT].shape[0])\n",
    "print('Spam messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SPAM].shape[0])\n",
    "print('Smishing messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SMISHING].shape[0])\n",
    "\n",
    "dataset = dataset[((dataset[COLUMN_LABEL] == LABEL_LEGIT) | (dataset[COLUMN_LABEL] == LABEL_SPAM))]\n",
    "# Let's check if they are gone\n",
    "#print('Smishing messages:', dataset[dataset[COLUMN_LABEL] == LABEL_SMISHING].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages2vectors(messages):\n",
    "    '''\n",
    "    Transforms single message into feature-vector;\n",
    "    Parameters:\n",
    "        messages    -   array of strings;\n",
    "    Returns:\n",
    "        features    -   array of feature-vectors;\n",
    "    '''\n",
    "\n",
    "    elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\")\n",
    "\n",
    "    features = np.zeros((0, 1024))\n",
    "    n = 100\n",
    "    l = int(len(messages) / n) if len(messages) % n == 0 else int(len(messages) / n) + 1\n",
    "    for i in range(l):\n",
    "\n",
    "        if (i + 1) * n < len(messages):\n",
    "            right = (i + 1) * n\n",
    "            embedds = elmo(messages[int(i * n) : right], signature=\"default\", as_dict=True)[\"default\"]\n",
    "        else:\n",
    "            embedds = elmo(messages[:len(messages) - int(i * n)], signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            embedds = sess.run(embedds)\n",
    "            features = np.concatenate([features, embedds])\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(labels_raw):\n",
    "    '''\n",
    "    Transforms labels into numerical values;\n",
    "    Parameters:\n",
    "        labels_raw    -   array of text-labels;\n",
    "    Returns:\n",
    "        features    -   array of numerical labels;\n",
    "    '''\n",
    "\n",
    "    labels = labels_raw.replace('LEGI', 0)\n",
    "    labels = labels.replace('SPAM', 1)\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's transform messages to features and change labels to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 1024)\n",
      "(1280,)\n"
     ]
    }
   ],
   "source": [
    "features = messages2vectors(dataset[COLUMN_TEXT])\n",
    "labels = convert_labels(dataset[COLUMN_LABEL])\n",
    "#print(features)\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "#print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(features, labels, ratio=0.7):\n",
    "    '''\n",
    "    Splits dataset into train/test parts using given ratio;\n",
    "    Parameters:\n",
    "        data    -   array of features;\n",
    "        labels  -   array of corresponding labels;\n",
    "        ratio   -   train/test size ratio;\n",
    "    Returns:\n",
    "        train_data      -   array of training features;\n",
    "        train_labels    -   array of training labels;\n",
    "        test_data       -   array of testing features;\n",
    "        test_labels     -   array of testing labels;\n",
    "    '''\n",
    "\n",
    "    positive_data = features[labels == 1]  # all spam features\n",
    "    negative_data = features[labels == 0]  # all legit features\n",
    "\n",
    "    # We shuffle arrays to get random samples later\n",
    "    random_indecies_positive = np.arange(positive_data.shape[0])\n",
    "    np.random.shuffle(random_indecies_positive)\n",
    "    random_indecies_negative = np.arange(negative_data.shape[0])\n",
    "    np.random.shuffle(random_indecies_negative)\n",
    "\n",
    "    n_positive_train = int(positive_data.shape[0] * ratio)\n",
    "    n_negative_train = int(negative_data.shape[0] * ratio)\n",
    "\n",
    "    # Training data are all indecies in 'ratio' part of shuffled indecies\n",
    "    train_data = np.concatenate([positive_data[random_indecies_positive[:n_positive_train]],\n",
    "                                 negative_data[random_indecies_negative[:n_negative_train]]])\n",
    "\n",
    "    train_labels = np.asarray([1] * n_positive_train + [0] * n_negative_train)\n",
    "\n",
    "    # Testing data are all indecies that remain\n",
    "    test_data = np.concatenate([positive_data[random_indecies_positive[n_positive_train:]],\n",
    "                                negative_data[random_indecies_negative[n_negative_train:]]])\n",
    "\n",
    "    test_labels = np.asarray(\n",
    "        [1] * (positive_data.shape[0] - n_positive_train) + [0] * (negative_data.shape[0] - n_negative_train))\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(labels, predictions):\n",
    "    '''\n",
    "    Computes metrics;\n",
    "    Parameters:\n",
    "        labels    -   array of labels;\n",
    "        predictions  -   array of predictions;\n",
    "    Returns:\n",
    "        FAR -   False Acceptance Rate;\n",
    "        FRR -   False Rejection Rate;\n",
    "    '''\n",
    "    #confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "    print(pd.DataFrame(confusion_matrix(labels, predictions),\n",
    "                       columns=['Predicted Spam', \"Predicted Legi\"], index=['Actual Spam', 'Actual Legi']))\n",
    "    '''\n",
    "    print(f'\\nTrue Positives: {tp}')\n",
    "    print(f'False Positives: {fp}')\n",
    "    print(f'True Negatives: {tn}')\n",
    "    print(f'False Negatives: {fn}')\n",
    "    '''\n",
    "    FAR = fn/(fn+tp)\n",
    "    FRR = fp/(fp+tn)\n",
    "    return FAR, FRR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(classifierType, hyperparameters, features, labels):\n",
    "    '''\n",
    "    Splits dataset into train/test parts using given ratio;\n",
    "    Parameters:\n",
    "        classifierType      -   type of ML algorithm to use;\n",
    "        hyperparameters     -   dictionary of model's parameters;\n",
    "        features            -   array of features;\n",
    "        labels              -   array of labels\n",
    "    Returns:\n",
    "        trainFAR    -   False Acceptance Rate for train dataset;\n",
    "        trainFRR    -   False Rejection Rate for train dataset;\n",
    "        testFAR     -   False Acceptance Rate for test dataset;\n",
    "        testFRR    -   False Rejection Rate for test dataset;\n",
    "    '''\n",
    "\n",
    "    model = classifierType(**hyperparameters)\n",
    "\n",
    "    # Split data\n",
    "    train_data, train_labels, test_data, test_labels = split_data(features, labels)\n",
    "\n",
    "    print('Train set shape:', train_data.shape)\n",
    "    print('Train labels shape:', train_labels.shape)\n",
    "    print('Test set shape:', test_data.shape)\n",
    "    print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "    # Fit your model\n",
    "    model=model.fit(train_data, train_labels)\n",
    "\n",
    "    # Make predictions for training dataset\n",
    "    print(\"---TRAINING---\")\n",
    "    prediction_train=model.predict(train_data)\n",
    "\n",
    "    # Compute train FAR/FRR\n",
    "    trainFAR, trainFRR = get_metrics(train_labels, prediction_train)\n",
    "\n",
    "    # Make predictions for testing dataset\n",
    "    predictions_test = model.predict(test_data)\n",
    "\n",
    "    # Compute test FAR/FRR\n",
    "    print(\"---TESTING---\")\n",
    "    testFAR, testFRR = get_metrics(test_labels, predictions_test)\n",
    "\n",
    "    return trainFAR, trainFRR, testFAR, testFRR\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--RANDOM FOREST CLASSIFIER--\n",
      "Train set shape: (895, 1024)\n",
      "Train labels shape: (895,)\n",
      "Test set shape: (385, 1024)\n",
      "Test labels shape: (385,)\n",
      "---TRAINING---\n",
      "             Predicted Spam  Predicted Legi\n",
      "Actual Spam             783               0\n",
      "Actual Legi               4             108\n",
      "---TESTING---\n",
      "             Predicted Spam  Predicted Legi\n",
      "Actual Spam             333               3\n",
      "Actual Legi              20              29\n",
      "(0.03571428571428571, 0.0, 0.40816326530612246, 0.008928571428571428)\n"
     ]
    }
   ],
   "source": [
    "classifierType1 = sklearn.ensemble.RandomForestClassifier\n",
    "hyperparameters1 = {'n_estimators' : 600,\n",
    "                'criterion' : 'entropy',\n",
    "                'max_depth': 8,\n",
    "                'min_samples_split' : 3,\n",
    "                'min_samples_leaf': 1,\n",
    "                'min_weight_fraction_leaf': 0.0,\n",
    "                'max_features': 'auto',\n",
    "                'max_leaf_nodes': None,\n",
    "                'min_impurity_decrease': 0}\n",
    "print(\"--RANDOM FOREST CLASSIFIER--\")\n",
    "print(evaluate(classifierType1, hyperparameters1, features, labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--NATIVE BAYES BERNOULLI--\n",
      "Train set shape: (895, 1024)\n",
      "Train labels shape: (895,)\n",
      "Test set shape: (385, 1024)\n",
      "Test labels shape: (385,)\n",
      "---TRAINING---\n",
      "             Predicted Spam  Predicted Legi\n",
      "Actual Spam             672             111\n",
      "Actual Legi              12             100\n",
      "---TESTING---\n",
      "             Predicted Spam  Predicted Legi\n",
      "Actual Spam             287              49\n",
      "Actual Legi               7              42\n",
      "(0.10714285714285714, 0.1417624521072797, 0.14285714285714285, 0.14583333333333334)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    }
   ],
   "source": [
    "classifierType2 = sklearn.naive_bayes.BernoulliNB\n",
    "hyperparameters2 = {'alpha':0.0,\n",
    "                'binarize':0.0,\n",
    "                'fit_prior':False,\n",
    "                'class_prior':None,\n",
    "                'fit_prior': True}\n",
    "print(\"--NATIVE BAYES BERNOULLI--\")\n",
    "print(evaluate(classifierType2, hyperparameters2, features, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PassaveAgressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--PASSIVEAGRESSIVE CLASSIFIER--\n",
      "Train set shape: (895, 1024)\n",
      "Train labels shape: (895,)\n",
      "Test set shape: (385, 1024)\n",
      "Test labels shape: (385,)\n",
      "-- Epoch 1\n",
      "Norm: 1.53, NNZs: 1024, Bias: -0.032712, T: 895, Avg. loss: 0.317566\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.93, NNZs: 1024, Bias: -0.064499, T: 1790, Avg. loss: 0.158851\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.22, NNZs: 1024, Bias: -0.070242, T: 2685, Avg. loss: 0.115983\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.44, NNZs: 1024, Bias: -0.077292, T: 3580, Avg. loss: 0.114940\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.62, NNZs: 1024, Bias: -0.073841, T: 4475, Avg. loss: 0.087990\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.76, NNZs: 1024, Bias: -0.079100, T: 5370, Avg. loss: 0.069180\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2.91, NNZs: 1024, Bias: -0.076464, T: 6265, Avg. loss: 0.069540\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 3.03, NNZs: 1024, Bias: -0.084055, T: 7160, Avg. loss: 0.060864\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 3.15, NNZs: 1024, Bias: -0.090676, T: 8055, Avg. loss: 0.064146\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 3.24, NNZs: 1024, Bias: -0.092415, T: 8950, Avg. loss: 0.055296\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 3.34, NNZs: 1024, Bias: -0.093705, T: 9845, Avg. loss: 0.052050\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 3.40, NNZs: 1024, Bias: -0.099103, T: 10740, Avg. loss: 0.043069\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 3.48, NNZs: 1024, Bias: -0.090352, T: 11635, Avg. loss: 0.047853\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 3.54, NNZs: 1024, Bias: -0.097899, T: 12530, Avg. loss: 0.044023\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 3.61, NNZs: 1024, Bias: -0.084119, T: 13425, Avg. loss: 0.047759\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 15 epochs took 0.04 seconds\n",
      "---TRAINING---\n",
      "             Predicted Spam  Predicted Legi\n",
      "Actual Spam             779               4\n",
      "Actual Legi               2             110\n",
      "---TESTING---\n",
      "             Predicted Spam  Predicted Legi\n",
      "Actual Spam             334               2\n",
      "Actual Legi               6              43\n",
      "(0.017857142857142856, 0.005108556832694764, 0.12244897959183673, 0.005952380952380952)\n"
     ]
    }
   ],
   "source": [
    "classifierType3 = sklearn.linear_model.PassiveAggressiveClassifier\n",
    "hyperparameters3 = {'C':0.5,\n",
    "                    'fit_intercept':True,\n",
    "                    'max_iter':1000,\n",
    "                    'tol':0.0001,\n",
    "                    'early_stopping':False,\n",
    "                    'n_iter_no_change':3,\n",
    "                    'shuffle':True,\n",
    "                    'verbose':2,\n",
    "                    'loss':'hinge',\n",
    "                    'n_jobs':None,\n",
    "                    'random_state':None,\n",
    "                    'warm_start':False,\n",
    "                    'class_weight':None,\n",
    "                    'average':False}\n",
    "\n",
    "print(\"--PASSIVEAGRESSIVE CLASSIFIER--\")\n",
    "print(evaluate(classifierType3, hyperparameters3, features, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
